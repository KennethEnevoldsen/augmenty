{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kennethenevoldsen/augmenty/blob/main/docs/tutorials/introduction.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "Augmenty is an augmentation library based on spaCy for augmenting texts. Augmenty differs from other augmentation libraries in that it corrects (as far as possible) the token, sentence and document labels under the augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "Before we get ahead of ourselves let us just install the required packages:\n",
    "\n",
    "``` bash\n",
    "pip install augmenty\n",
    "# install the spacy pipeline\n",
    "python -m spacy download en_core_web_md\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Augmenty is an augmentation library for spaCy, consisting of many different augmenters. To get an idea of all the available augmenters you can always try out the use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spacy.combined_augmenter.v1\n",
      "spacy.orth_variants.v1\n",
      "spacy.lower_case.v1\n",
      "random_casing_v1\n",
      "char_replace_random_v1\n",
      "char_replace_v1\n",
      "keystroke_error_v1\n",
      "remove_spacing_v1\n",
      "char_swap_v1\n",
      "upper_case_v1\n",
      "spongebob_v1\n",
      "paragraph_subset_augmenter_v1\n",
      "random_starting_case_v1\n",
      "conditional_token_casing_v1\n",
      "token_insert_v1\n",
      "token_insert_random_v1\n",
      "duplicate_token_v1\n",
      "random_synonym_insertion_v1\n",
      "token_dict_replace_v1\n",
      "wordnet_synonym_v1\n",
      "token_replace_v1\n",
      "word_embedding_v1\n",
      "letter_spacing_augmenter_v1\n",
      "spacing_insertion_v1\n",
      "token_swap_v1\n",
      "da_æøå_replace_v1\n",
      "da_historical_noun_casing_v1\n",
      "ents_replace_v1\n",
      "per_replace_v1\n",
      "ents_format_v1\n"
     ]
    }
   ],
   "source": [
    "import augmenty\n",
    "\n",
    "augmenters = augmenty.augmenters()\n",
    "\n",
    "for augmenter in augmenters:\n",
    "    print(augmenter)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get get more information about an individual augmenter you can always simply use `help` for instance let is say you want to know more about the upper case augmenter you could run: `help(augmenters[\"upper_case_v1\"])`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have an idea about the augmenter you wish to use loading in augmenters in augmenty is made easy using the `load` command given and given the arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_case_augmenter = augmenty.load(\"upper_case_v1\", level=1.00)  # 100% uppercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the augmentation\n",
    "Augmenters in augmenty always take in a spaCy [Language pipeline](https://spacy.io/api/language) and an spaCy [Example](https://spacy.io/api/example) so that it can be easily used while training workflows, however, augmenty also allows for easy application of augmenters to raw text and spaCy [Docs](https://spacy.io/api/doc).\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Why examples and not just raw text?**\n",
    "\n",
    "\n",
    "A spaCy example consist of two documents, the labelled document, containing all the correct labels including document classification such as whether a tweet is positive or negative and token classiification such as Part-of-speech-tags and named entities. When augmenting the Example augmenty seeks to correct these tags in accordance with the augmentation. As the raw text does not include these labels it as naturally not possible. For instance if I was to swap two tokens I would want to swap their corresponding labels as well. When swapping tokens augmenty even respect entities and sentences as to not split an entity or swap tokens across sentence borders. You can naturally turn this of if you wish to.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying augmentations on Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUGMENTATION IS A WONDERFUL TOOL FOR OBTAINING HIGHER PERFORMANCE ON LIMITED DATA.\n",
      "YOU CAN ALSO USE IT TO SEE HOW ROBUST YOUR MODEL IS TO CHANGES.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "docs = nlp.pipe(\n",
    "    [\n",
    "        \"Augmentation is a wonderful tool for obtaining higher performance on limited data.\",\n",
    "        \"You can also use it to see how robust your model is to changes.\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "augmented_docs = augmenty.docs(docs, augmenter=upper_case_augmenter, nlp=nlp)\n",
    "\n",
    "for doc in augmented_docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying augmentations on text\n",
    "We can also try it out on text. Let us also try out a new augmenter for replacing entities. Remember you can always use `help(augmenters[\"ents_replace.v1\"])` to figure out which inputs the augmenter takes and see and example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenty is a wonderful tool for augmentation which is made using SpaCy developed by The SpaCy Universe.\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Augmenty is a wonderful tool for augmentation which is made using SpaCy developed by Explosion.\"\n",
    "]\n",
    "\n",
    "ent_augmenter = augmenty.load(\n",
    "    \"ents_replace_v1\", level=1.00, ent_dict={\"ORG\": [[\"The SpaCy Universe\"]]}\n",
    ")\n",
    "\n",
    "augmented_texts = augmenty.texts(texts, augmenter=ent_augmenter, nlp=nlp)\n",
    "\n",
    "for text in augmented_texts:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing augmenters\n",
    "Augmenty is more than a list of augmenters and also contains utilities for dealing with augmenters such as combining and moderating augmenters. \n",
    "\n",
    "### Combining augmenters\n",
    "We can start of by combing the entity augmenter with an augmenter which replaces words with their synonym based on wordnet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_augmenter = augmenty.load(\"wordnet_synonym_v1\", level=1, lang=\"en\")\n",
    "\n",
    "combined_aug = augmenty.combine([ent_augmenter, synonym_augmenter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenty is a fantastic shaft for augmentation.\n"
     ]
    }
   ],
   "source": [
    "augmented_texts = augmenty.texts(texts, augmenter=combined_aug, nlp=nlp)\n",
    "\n",
    "for text in augmented_texts:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moderating Augmenters\n",
    "Certain augmenters apply augmentation at different levels. For instance the augmenter `keystroke_error.v1` augments examples based on keyboard distances, where each character has a chance to be replaced with a neightbouring character. However, we might wish to apply this augmentation to 5% of characters, but only apply it 50% of the training samples. Using `augmenty.set_doc_level` we can add this last part to any augmenter, thus allowing for more flexibility when using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keystroke_augmenter = augmenty.load(\n",
    "    \"keystroke_error_v1\", keyboard=\"en_qwerty_v1\", level=0.05\n",
    ")  # 5% if characters\n",
    "\n",
    "keystroke_augmenter = augmenty.set_doc_level(\n",
    "    keystroke_augmenter, level=0.5\n",
    ")  # 50% of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenty is a wonderful tool for augmentation.\n",
      "Augmentation is q wonderful tool for obtain6ng higher performance on li,ited data.\n",
      "You cxn also use it to see how robush your model is to changes.\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Augmenty is a wonderful tool for augmentation.\",\n",
    "    \"Augmentation is a wonderful tool for obtaining higher performance on limited data.\",\n",
    "    \"You can also use it to see how robust your model is to changes.\",\n",
    "]\n",
    "\n",
    "augmented_texts = augmenty.texts(texts, augmenter=keystroke_augmenter, nlp=nlp)\n",
    "\n",
    "for text in augmented_texts:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly one might wish the augment to instead of simply yielding the augmented example also yield the original, such that the trained model always see the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenty is a tool wonderful for augmentation.\n",
      "Augmenty is a wonderful tool for augmentation.\n",
      "is Augmentation wonderful a tool obtaining for higher performance on limited data.\n",
      "Augmentation is a wonderful tool for obtaining higher performance on limited data.\n",
      "You can also use it to see how robust your is model to changes.\n",
      "You can also use it to see how robust your model is to changes.\n"
     ]
    }
   ],
   "source": [
    "token_swap_augmenter = augmenty.load(\"token_swap_v1\", level=0.20)\n",
    "token_swap_augmenter = augmenty.yield_original(\n",
    "    token_swap_augmenter\n",
    ")  # yield both the augmented and original example\n",
    "\n",
    "augmented_texts = augmenty.texts(texts, augmenter=token_swap_augmenter, nlp=nlp)\n",
    "\n",
    "for text in augmented_texts:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying augmentation to Examples or a Corpus\n",
    "Examples consists of two docs, one containing the predictions of the model, the other containing the gold labelled document. For this example we will load the DaNE dataset. DaNE includes the Danish dependency treebank additionally tagged for named entities. Here we will use synonym replacement to augment a corpus.\n",
    "\n",
    "To load the corpus we will use [DaCy](https://centre-for-humanities-computing.github.io/DaCy/) which we will install using:\n",
    "``` bash\n",
    "pip install dacy\n",
    "```\n",
    "\n",
    "And then we can apply the methods:\n",
    "\n",
    "```python\n",
    "from dacy import datasets\n",
    "\n",
    "train, dev, test = datasets.dane(splits=[\"train\", \"dev\", \"test\"])\n",
    "\n",
    "from spacy.lang.da import Danish\n",
    "\n",
    "nlp_da = Danish()\n",
    "\n",
    "synonym_augmenter = augmenty.load(\"wordnet_synonym.v1\", level=0.2, lang=\"da\")\n",
    "augmented_corpus = [\n",
    "    e for example in test(nlp_da) for e in synonym_augmenter(nlp_da, example)\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Faker for entity replacing\n",
    "Augmenty allow for easy integrations of existing libraries such as [Faker](https://faker.readthedocs.io/en/master/index.html). \n",
    "Faker is an open-source python library which can generate various \n",
    "entities such as names. It is compatibile with multiple languages and has a lot of language-specific entity generators.\n",
    "\n",
    "To install Faker:\n",
    "``` bash\n",
    "pip install faker\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from faker import Faker\n",
    "\n",
    "nlp_en = spacy.load(\"en_core_web_lg\")\n",
    "texts = \"my name is Kenneth Enevoldsen\"\n",
    "doc = nlp_en(texts)\n",
    "\n",
    "# entity replace augmenter takes a generator returning list of strings\n",
    "fake = Faker()\n",
    "\n",
    "\n",
    "def faker_name():\n",
    "    while True:\n",
    "        yield fake.name().split()\n",
    "\n",
    "\n",
    "ent_dict = {\"PERSON\": faker_name()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my name is Leah White\n"
     ]
    }
   ],
   "source": [
    "ent_augmenter = augmenty.load(\"ents_replace_v1\", level=1.00, ent_dict=ent_dict)\n",
    "\n",
    "docs = list(augmenty.docs([doc], augmenter=ent_augmenter, nlp=nlp_en))\n",
    "print(docs[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Contributing Augmenters\n",
    "\n",
    "After using augmenty you might want to create and contribute an augmenter. Most augmenters can be created based on already existing augmenters. For instance the augmenter `per_replace_v1`, which replaces names in a text is a spacial case of the augmenter `ents_replace_v1` with better handling of first and last names. If you want to create an augmenter from scratch following spaCy's [guide](https://spacy.io/usage/training#data-augmentation-custom) on creating custom augmenters is a good start. You can always use augmenters from augmenty as inspiration as well. If you find yourself in troubles feel free to ask in the [augmenty forums](missing). \n",
    "\n",
    "When you are satisfied with your augmenter feel free submit a [pull request](https://github.com/KennethEnevoldsen/augmenty/pulls) to add the augmenter to augmenty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('augmenty')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "ba80f47275333c3291565a329c6965245f24799efa9ebd03a2c8dc9d40380264"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
